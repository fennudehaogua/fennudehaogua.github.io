<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Steganography," />








  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=5.1.2" />






<meta name="description" content="A Survey of Image Information Hiding Algorithms Based on Deep Learning(2018,CR3) 摘要： 随着数据科学技术的发展，信息安全问题日益受到人们的关注。为了解决个人隐私被偷窥、版权被侵犯等隐私问题，开发了信息隐藏算法。图像信息隐藏是利用cover图像的冗余来隐藏其中的秘密信息。确保stego图像与cover图像无法区分，并通">
<meta name="keywords" content="Steganography">
<meta property="og:type" content="article">
<meta property="og:title" content="A Survey of Image Information Hiding Algorithms Based on Deep Learning(2018,CR3)">
<meta property="og:url" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/index.html">
<meta property="og:site_name" content="fennudehaogua.top">
<meta property="og:description" content="A Survey of Image Information Hiding Algorithms Based on Deep Learning(2018,CR3) 摘要： 随着数据科学技术的发展，信息安全问题日益受到人们的关注。为了解决个人隐私被偷窥、版权被侵犯等隐私问题，开发了信息隐藏算法。图像信息隐藏是利用cover图像的冗余来隐藏其中的秘密信息。确保stego图像与cover图像无法区分，并通">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/edd2cc81cf533f9c9e836afcf02194f0.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/bacd710d80b67abf8037f0d5ba84e00e.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/15100bf6174d26978192cbcfabfd339c.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/2e7f6032629f46fe1f4416c6a44526c8.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/d638a686f409151d3d5e5383b3b01013.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/396f16822255ca186bfba8afb62e0af5.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/a4cc1f636125635c6f69fabae1643554.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/c5dbd2c1662177bfae1c6234deba759f.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/319e8f2bf696e16bb9fd9ac38b9594ea.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/f4850bf4d687950c0e188c3138a32a27.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/a6ccb1958c655832eeb724d2eb9bdb6c.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/1d400d9196090910b6a5ee017ea009d7.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/7e2d79da6c46f2c8e8a26520b167226a.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/163be0e29f26ee47786a70350056ec3b.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/664228982c0eaee070dea74eaf4d7439.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/68ff4a110ca801c7cee5d4b5285bfeaf.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/7935eb3e48bd424e58a0d432f78f4d21.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/a2e3c535da76ae4fea15904ddaa292ec.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/7b185cdfae1e9dc9619aba77d6c1dcef.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/dcc81efa1910402f75558d68e76cfa04.png">
<meta property="og:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/b1d80a8c874f0822db04ce92e3cf731a.png">
<meta property="og:updated_time" content="2019-10-10T12:51:06.385Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Survey of Image Information Hiding Algorithms Based on Deep Learning(2018,CR3)">
<meta name="twitter:description" content="A Survey of Image Information Hiding Algorithms Based on Deep Learning(2018,CR3) 摘要： 随着数据科学技术的发展，信息安全问题日益受到人们的关注。为了解决个人隐私被偷窥、版权被侵犯等隐私问题，开发了信息隐藏算法。图像信息隐藏是利用cover图像的冗余来隐藏其中的秘密信息。确保stego图像与cover图像无法区分，并通">
<meta name="twitter:image" content="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/edd2cc81cf533f9c9e836afcf02194f0.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"right","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/"/>





  <title>A Survey of Image Information Hiding Algorithms Based on Deep Learning(2018,CR3) | fennudehaogua.top</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?727b9992a1a14607aebb47500e5bcc08";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










    <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail ">
    <div class="headband"></div>
    <a href="https://github.com/fennudehaogua"><img style="position: absolute; top: 0; left: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_left_red_aa0000.png" alt="Fork me on GitHub"></a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">fennudehaogua.top</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">好记性不如烂笔头</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://fennudehaogua.top/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wu Tian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/jiansheng.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="fennudehaogua.top">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">A Survey of Image Information Hiding Algorithms Based on Deep Learning(2018,CR3)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-29T20:26:54+08:00">
                2019-09-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Steganography/" itemprop="url" rel="index">
                    <span itemprop="name">Steganography</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><strong>A Survey of Image Information Hiding Algorithms Based on Deep Learning(2018,CR3)</strong></p>
<h2 id="摘要："><a href="#摘要：" class="headerlink" title="摘要："></a>摘要：</h2><hr>
<p>随着数据科学技术的发展，信息安全问题日益受到人们的关注。为了解决个人隐私被偷窥、版权被侵犯等隐私问题，开发了信息隐藏算法。图像信息隐藏是利用cover图像的冗余来隐藏其中的秘密信息。确保stego图像与cover图像无法区分，并通过传输stego图像向接收者发送秘密信息。目前，基于深度学习的模型也被广泛应用于信息隐藏领域。本文对基于深度学习的图像信息隐藏进行了全面的总结。它分为四部分:隐写算法、水印嵌入算法、无载体信息隐藏算法和基于深度学习的隐写分析算法。从这四个方面对基于深度学习的信息隐藏技术进行了阐述和分析。</p>
<p>索引词：隐写术，深度学习，隐写分析，水印，无载体信息隐藏。</p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><hr>
<p>随着信息时代的到来，越来越多的人使用移动设备进行交流、工作和创造。它给我们的生活和工作带来了极大的方便。但越来越多的安全问题暴露了出来。例如，个人隐私被窥探、传播、被盗作品、版权所有等等。在解决这类问题的过程中，信息隐藏已经成为保护隐私和版权的重要手段。信息隐藏意味着利用cover图片的一些特点将秘密信息隐藏在cover图片,并在cover图片的传播的过程中,没有发现任何异常的探测器,以便stego图像可以安全地传输到接收器。接收者通过一定的算法提取秘密信息，实现秘密通信。其中，机密信息可以是一段文字、一张图片等等。在隐藏过程中，通常的方法是将秘密信息转换为比特流，并将比特信息隐藏在隐藏媒体中。此外，还可以将图像直接隐藏在另一幅图像中，或者将秘密信息对应到映射字典中，将包含映射对象的信息传输给接收方。隐写术是一种隐蔽的通信手段，在国家安全和军事事务中具有重要意义。然而，在维护网络通信安全的同时，也有一些不具备良好意图的人使用隐写术。事实上，信息隐藏近年来也被用于间谍、恐怖袭击、犯罪等活动中。在这种情况下，如何对隐写术进行有效的监督，防止和阻止其恶意或非法的应用，已经成为各国军事和安全部门迫切需要解决的问题。因此，隐写分析在信息隐藏技术的发展中得到了广泛的关注和发展。隐写分析是指探测器在发布隐写图像后，判断该隐写图像是否含有秘密信息的过程。隐写和隐写分析是两种既相互制约又相互对立的算法。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><hr>
<h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><p>2006年，G.E. Hinton等[Hinton and Salakhutdinov(2006)]提出了一种无监督预训练的方法，通过优化网络权值的初值，再对权值进行细化，拉开了深度学习的序幕。深度学习本质上分为三种类型:<strong>监督学习、非监督学习和强化学习</strong>。<strong>监督学习</strong>是指在输入数据中同时具有特征值和标签值的机器学习。通过计算网络输出值与标签值之间的误差，期望对网络进行迭代训练，找出最佳输出值。监督学习中需要解决的问题可以分为两类:回归[Fu,Gong, Wang et al.(2018)]和分类[Gurusamy and Subramaniam (2017);Yuan, Li,Wu等(2017)]。图像分类作为一项重要的分类任务，是一个备受关注的研究领域。ImageNet[Russakovsky, Deng, Su et al.(2014)]对1000个类别的分类，促进了CNN的发展，如VGG[Simonyan and Zisserman(2014)]和ResNet [He, Zhang, Ren et al.(2016)]。目前流行的监督学习算法有卷积神经网络(CNN)和深度信念网络(DBN)。极限学习机[Gautam, Tiwari and Leng(2017)]是一种基于前馈神经元网络的机器学习。它也是一种监督学习。它用于预测[Dutta, Murthy, Kim et al.(2017)]、分类等。<strong>无监督学习</strong>的目的是通过机器学习发现输入数据的一些共同特征、结构或特征值之间的相关性。无监督学习方法如自动编码器[Kingma and Welling(2013)]、深度玻耳兹曼机<a href="RBM">Montavon and Muller (2012)</a>和当前流行的生成式对抗网络(GAN) [Goodfellow, Pouget-Abadie, Mirza et al.(2014)]。<strong>强化学习</strong>[Mnih, Kavukcuoglu, Silver et al.(2015)]强调如何对环境采取行动以最大化预期收益。在应用上，深度学习在视频领域得到了很大的发展[Feichtenhofer, Fan, Malik et al. (2018);Wichers, Villegas,Erhan等(2018);Wang, Liu, Zhu等(2018)]，图像 [Xie, He, Zhang等(2018);Barz and Denzler (2018);Wang and Chan(2018)]， 语音 [Yang, Lalitha, Lee et al. (2018);Arik, Chen, Peng等(2018);Qian,Du, Hou等(2017)]，语义理解[Qin, Kamnitsas, Ancha等(2018); Zhuang and Yang(2018);Sanh, Wolf and Ruder(2018)]，并已进一步应用于目标检测[Roddick, Kendalland Cipolla (2018);Jaeger, Kohl, Bickelhaupt等(2018)]，图像取证[Yu, Zhan and Yang(2016)，Cui，McIntosh and Sun(2018)]，智能管理[Liang，Jiang，Chen等(2018);Le, Pham, Sahoo等(2018);Duan, Lou, Wang等人(2017)]和医 [Mobadersany, Yousefi, Amgad等人(2018);Rajpurkar,Irvin, Zhu等(2017);Akkus, Galimzianova, Hoogi等(2017)]。</p>
<p><strong>在监督学习领域，</strong>基于深度学习的图像分类方法已经成熟，可以应用于目标检测和图像检索。目标检测是指在数字图像或视频中检测对象的类别(如狗、车辆或人)。fast R-CNN [Ren, He, Girshick et al.(2015)]、R-FCN [Dai, Li, He et al.(2016)]、YOLO [Redmon, Divvala, Girshick et al.(2016)]和SSD [Liu, Anguelov, Erhan et al.(2016)]是基于深度学习的四种应用最广泛的对象检测模型。与传统方法相比，当传统方法不能有效识别特征时，CNN可以更好地处理任务。</p>
<p><strong>在无监督学习领域，</strong>GAN是一个典型的代表。GAN的基本原理是它有两个模型:生成器和鉴别器。鉴别器的任务是确定给定的数据是否看起来“自然”，换句话说，它是否由机器生成。生成器的任务是不断捕获训练数据库中的数据，从而生成看似“自然”的数据，这就要求原始数据的分布尽可能一致。目前，GAN广泛应用于图像、视觉、语言等领域。此外，GAN还可以与<strong>强化学习</strong>相结合。Arjovsky等人在2017年提出的WGAN(Wasserstein GAN)有效地优化了GAN [Arjovsky, Chintala and Bottou(2017)]。它解决了GAN训练不稳定的问题，提出了保证生成样本多样性的有效方法，使用特定的交叉熵函数来表示训练过程，使用多层神经网络完成训练而不需要设计特定的网络结构。最小二乘GAN(LSGAN) [Mao, Li, Xie et al.(2017)]通过在鉴别器中使用更平滑的非饱和梯度损失函数对GAN进行优化。Hjelm等[Hjelm,Jacob,Che等(2017)]改进了GAN模型，该模型是一种边界寻求GAN。它使用离散的输出来训练生成器。最大似然增强离散GAN<br>[Che, Li, Zhang et al.(2017)]利用对数似然后的相应输出推导出新的低方差目标。模式正规化GAN [Che, Li, Jacob et al.(2016)]有助于在训练初期的数据生成和分布模式中实现公平的概率质量分布，从而为缺失模式的问题提供统一的解决方案。在Brock等人[Brock, Donahue 和 Simonyan (2018)],在高分辨率下有了新成果，令人印象深刻的成就。基于GAN设计了图像风格转换的最新研究进展[karras,Laine and Aila (2018);Zhu, Park, Isola等(2017);Yi，Zhang，Tan等(2017);Kim, Cha,Kim等(2017)]。训练过程的目的是减少两个转化目标之间的迁移损失。</p>
<h3 id="信息隐藏"><a href="#信息隐藏" class="headerlink" title="信息隐藏"></a>信息隐藏</h3><p>信息隐藏技术有着悠久的历史。最初，人们用头发来掩盖秘密信息，把秘密信息藏在头皮里，等待头发长出来，从而传递军事信息。在计算机飞速发展的时代，信息隐藏领域发展迅速。在图像信息隐藏领域，早期最具代表性的信息隐藏算法是空间最小有效位(LSB)隐写算法。该算法利用人眼对颜色的不敏感，将秘密信息隐藏到每个像素的最低有效位，从而传输秘密信息。对于彩色图像，它们通常由三个通道组成:红色(R)、绿色(G)和蓝色(B)，每个通道占用8位，范围从00x00到0Xff。LSB隐写是指修改RGB颜色分量的最低有效位。例如，对于R通道，假设R(x，y)=11011010，最低有效位为最后一位0，如果隐藏的秘密位为1，则最低有效位0变为1，最后R(x，y)=11011011;如果隐藏的秘密位为0，则不修改最低有效位，R(x，y)=11011010。LSB隐写算法的隐藏能力令人印象深刻，但难以抵抗统计特性。在空间域的隐写方法中，秘密信息的隐藏主要是通过计算像素值来实现的。典型的方法包括LSB置换[Wu,Wu, Tsai等(2005)]、LSB匹配[Mielikainen(2006);Xia，Wang，Sun等(2014);Xia，Wang，Sun 等。(2016)],多平面图像隐写术(MBPIS) (NguyenYoon和Li(2006))直方图算法(Li、Chen, Pan等。(2009)),调色板隐写(Johnson andJajodia (1998)], Multiple-Based符号系统(拥有)[ Zhang and Wang(2005)]量化索引调制(QIM)( Chen and Wornell(2001)]等等。对于频域隐写，主要通过修改某些特定的频率系数来隐藏秘密信息。变换算法有离散余弦变换(DCT)、傅里叶变换、离散小波变换(DWT)等。隐写术的方法通常分为两类，即JPEG隐写术[Westfeld(2001); Provos and Honeyman(2001); Sallee (2003); Provos and Honeyman(2003)]和离散小波变换隐写术[Al-Ataby and Al-Naima (2008); Yang and Deng (2006);Chen and Lin (2006);Talele and Keskar (2010)]。</p>
<p>为了提高保密信息传输的安全性，提出了S-UNIWARD [Holub, Fridrich and Denemark(2014)]、WOW [Holub and Fridrich(2012)]、HUGO [Pevny, fill and Bas(2010)]等图像自适应隐写算法。这些算法根据图像像素的嵌入失真，通过设置失真阈值来选择纹理复杂的区域。如图1所示，HUGO,S-UNIWARD和WOW的效果图比较。从stego图像与cover图像的比较来看，很难直观地检测出stego图像的异常。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/edd2cc81cf533f9c9e836afcf02194f0.png" alt=""></p>
<h3 id="水印"><a href="#水印" class="headerlink" title="水印"></a>水印</h3><p>在数字媒体得到广泛应用的今天，数字媒体的修改和重用问题也受到了广泛的关注。为了解决数字媒体的版权问题，提出并开发了数字水印[Fridrich(1999);He, Zhang and Tai (2009); He, Chen, Tai et al.(2012)].。数字水印是指将数字、序列号、文字或图像标识的信息嵌入到音频、视频或图像中，从而起到版权保护、真实性识别、保密通信等作用。同时，在多媒体数据中嵌入水印后，可以对水印进行检测和提取。数字水印包括水印嵌入、水印检测和水印提取两个方面。数字水印虽然在很长一段时间内没有被提出，但它也得到了发展。水印算法分为六个方面，盲水印[Dorairangaswamy(2009); Eggers and Girod (2001); Kang and Lee (2006)]，半盲水印[Liu, Zhang, Chen(2009); Rahman, Ahammed, Ahmed et at. (2017)] 非盲水印[Gunjal and Mali (2015)]健壮水印[Deng, Gao, Li et al. (2009)], 脆弱水印[Chang, Fan and Tai (2008),Nazari, Sharif and Mollaeefar(2017)]和嵌入水印 [Wu, Hu, Gu et al.(2005)].近年来，深度学习与数字水印相互应用。在深度学习模型中，利用数字水印来保护深度学习模型的属性也是一种比较新的研究方法。利用深度学习方法提高数字水印的鲁棒性已经取得了一定的进展。</p>
<h3 id="无载体信息隐藏"><a href="#无载体信息隐藏" class="headerlink" title="无载体信息隐藏"></a>无载体信息隐藏</h3><p>信息隐藏是通过修改cover图像的像素来隐藏秘密信息。修改cover图像意味着可以被检测器检测到。为了彻底避免这个问题，从根本上抵制隐写分析，2014年专家提出了无载体信息隐藏。无载体信息隐藏是指<strong>利用秘密信息作为驱动程序，查找或生成与秘密信息对应的stego图像</strong>[Gunjal and Mali (2015); Zhou, Sun, Harit et al. (2015); Zhou, Cao and Sun (2016); Yuan, Xia and Sun (2016)]。在此过程中不需要更改cover图像。一般的方法是构造一个映射字典，形成秘密信息与特征信息之间的映射关系。发送方与接收方共享映射字典。通过将与秘密信息具有映射关系的自然图像或文本传输给接收者，接收者根据映射关系提取秘密信息，从而抵抗隐写分析。无载体信息隐藏领域有两个主要分支。一种是文本信息的无载体隐藏，即文本的传输。由于自然语言处理(NLP)的蓬勃发展，人们见证了这些算法在单词嵌入方面的有效性，如word2vec[Goldberg and Levy(2014)]和LSTM [Sak, Senior and Beaufays(2014)]。基于嵌入词与无载体文本信息隐藏映射关系具有很强的相似性，将NLP的先进知识与无载体文本信息隐藏相结合[Zhang, Huang, Wang et al. (2017); Long and Liu (2018); Zhang, Shen, Wang et al.(2016)]。另一种是图像的平移，称为图像的无载体信息隐藏[Duan and Song (2018)]。</p>
<h3 id="隐写分析"><a href="#隐写分析" class="headerlink" title="隐写分析"></a>隐写分析</h3><p>隐写分析用于确定隐写图像是否包含秘密信息，即执行二分类任务，即确定图像是stego图像还是cover图像。早期的隐写算法可以被人类的感知器官检测到，但是随着隐写算法的进一步发展，人类的感知器官无法对隐写图像进行识别，因此隐写分析可以通过分析图像的统计特征进行有效的识别。目前,基于复杂的高阶统计特性相关的图像隐写分析已经成为主流的特性,比如SRM/ SRMQ1(空间域富模型)[Fridrich和Kodovsky(2012)]和PSRM[Holub和Fridrich(2013)]基于高阶和高维特性模型,取得了良好的检测结果。有许多研究对特征的选择进行了评价。Chen等[Chen and Shi(2008)]提出了一种基于块马尔可夫特征的特征选择方法。Pevny等[Pevny and Fridrich(2007)]为隐写分析设计了PEV特性。CC-C300是Kodovsky等人[Kodovsky and Fridrich(2010)]提出的JPEG隐写分析高维富模型的一项尝试性工作。它开创了隐写分析高维特征的发展。Kodovsky等人[Kodovsky, Fridrich and Holub(2012)]改进了他们的算法，将其修剪为更紧凑的特征选择。考虑到DCT图像模式的典型特征，Kodovsky等[Kodovsky and Fridrich(2012)]提出CC-JRM**。Denemark等[Denemark, Fridrich and Holub(2014)]针对S-UNIWARD的检测，提出了图像内容选择的残差特征。为了降低隐写分析算法的复杂度，Holub等[Holub and Fridrich (2015a)]提出了从DCT域残差映射中提取特征的DCTR。Holub等[Holub and Fridrich (2015b)]提出的相位感知投影模型(phase-aware projection model, PHARM)是基于对JPEG网格特征的观察而设计的。Denemark el al. [Denemark, Fridrich and Comesana-Alfaro (2016);Denemark, Boroumand and Fridrich(2016)]提出了提取图像特征的算法。除了传统的基于人工特征的隐写分析方法外，基于深度学习的隐写分析方法也得到了进一步的发展。</p>
<h2 id="基于深度学习的图像信息隐藏技术"><a href="#基于深度学习的图像信息隐藏技术" class="headerlink" title="基于深度学习的图像信息隐藏技术"></a>基于深度学习的图像信息隐藏技术</h2><hr>
<p>深度学习在信息隐藏中的应用逐渐发展起来。由于深度学习的部分模型、特征和过程与信息隐藏相对应，因此可以应用于信息隐藏领域。此外，深度学习模型在应用于信息隐藏时，在分类方法的各个分支中也有不同程度的交叉应用。特别是GAN中的对抗性理论，自然对应于信息隐藏和检测。在潜在的隐写分析算法中，基于GAN的方法可以更有针对性地抵抗隐写分析。GAN在无载体信息隐藏中的应用可以通过映射字典生成合格的stego图像，其高质量的生成效果避免了检测。</p>
<h3 id="基于深度学习的隐写算法"><a href="#基于深度学习的隐写算法" class="headerlink" title="基于深度学习的隐写算法"></a>基于深度学习的隐写算法</h3><h4 id="对抗性方法的隐写算法"><a href="#对抗性方法的隐写算法" class="headerlink" title="对抗性方法的隐写算法"></a>对抗性方法的隐写算法</h4><p>由于GAN生成器和鉴别器具有对抗作用，使得生成的图像能够抵抗鉴别器的干扰。在GAN的基本应用中，该生成器模拟对象类别的分布，并将每个模拟的分布结果分别给出给鉴别器，用于真假图像的分类。如果确定图像是生成的图像，则将确定结果反馈给生成器，生成器根据反馈重新生成图像分布。通过这个过程的不断循环，最终生成一个相对真实的图像。在这个过程中，我们发现在生成器和鉴别器的对抗，以及隐写术和隐写分析的对抗之间，存在着一定的相似性。如图2所示，隐写术的过程是利用嵌入算法将秘密信息隐藏到cover图像中，得到stego图像。对于接收方，采用提取算法提取出隐式图像中的秘密信息;对于隐写分析，在stego图像公开之后，检测器通过确定隐写图像是否包含秘密消息来确定图像是cover图像还是stego图像。在GAN中，生成网络通过向生成器中输入一片噪声来生成图像。判别网络将假图像和真图像输入到判别器，判别器给出是否为真图像的结果，即判断生成图像的真实性。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/bacd710d80b67abf8037f0d5ba84e00e.png" alt=""></p>
<p>通过分析可以看出，GAN的结构完全对应于隐写术的结构。生成网络对应于隐写生成stego图像，判别网络对应于隐写分析判断是否为假(stego)图像。因此，许多论文将GAN应用于隐写术。实验证明，将隐写技术与GAN相结合，使隐写过程更加健壮，得到的stego图像更加隐蔽和安全。GAN的总优化函数如式(1)所示。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/15100bf6174d26978192cbcfabfd339c.png" alt=""></p>
<p>其中x表示输入数据，pz(z)为噪声变量，p(data)(x)为真实数据，D(x)表示x来自真实数据而不是生成数据的概率。</p>
<p>该方法最早由Hayes等人提出[Hayes and Danezis(2017)]。他们定义了一个三方游戏，Alice，Bob和Eve。Alice和Bob试图将秘密信息隐藏在图像中，用它进行秘密通信，Eve偷听了他们的谈话，并判断其中是否包含秘密信息。在这个过程中，三方都是神经网络。Alice是一个隐写构造函数，Eve是一个隐写分析，Bob是一个提取器。根据隐写分析的反馈，即识别器，对生成的stego图像进行调整。Bob从生成的stego图像中提取关于位的信息。Volkhonskiy等人[Volkhonskiy,Nazarov, Borisenko等人(2017)]提出了SGAN(隐写生成对抗网络)，主要增加了一个基于GAN的隐写分析鉴别器。如图3所示，SGAN的结构是一个发生器和两个鉴别器，分别是鉴别器和隐写分析器。利用鉴别器的作用判断图像是否真实，利用隐写分析器判断图像是否含有秘密信息。总优化函数如式(2)所示，将steganalyzer的优化函数添加到GAN模型的优化函数中。该方法降低了隐写分析的检出率，使信息隐藏更加安全。SGAN增加了基于DCGAN的鉴别器[Radford,Metz and Chintala(2015)]。SGAN的视觉效果如图4所示。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/2e7f6032629f46fe1f4416c6a44526c8.png" alt=""></p>
<p>其中，P(z)(z)是噪声变量，p(data)(x)为真实数据，Stego(x)代表stego图像，α为权重参数，它用于控制生成图像损失函数对鉴别器和隐写分析器的重要性。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/d638a686f409151d3d5e5383b3b01013.png" alt=""></p>
<p>Shi等[Shi, Dong,Wang等(2017)]<strong>在SGAN的基础上进行了改进。将SGAN的基本网络DCGAN转换为WGAN，生成的图像更加真实，图像质量更高，网络训练速度更快。</strong>此外，将隐写分析网络改进为GNCNN[Qian, Dong, Wang etal.(2015)]。通过GNCNN与生成器之间的对抗，增强了stego图像的隐蔽性和鲁棒性。Tang等[Tang,Tan,Li等(2017)]提出了一种新的框架ASDL-GAN，通过为cover图像寻找合适的隐写位置来实现隐写。此外，网络对鉴别器的结构进行了修改，将鉴别器改为Xu等人的隐写分析模型[Xu,Wu and Shi(2016)]。Yang等[Yang, Liu,Kang等(2018)]在ASDL-GAN的基础上做了三个改进:<strong>修改Tanh模拟器的激活功能，减少训练周期</strong>;基于U-NET改变生成器[Ronneberger,Fischer and Brox (2015)];将SCA [Denemark, Boroumand and Fridrich(2016)]添加到判别器中，以增强抵抗基于SCA的隐写分析方案的性能。Ma等人[Ma,Guan,Zhao等人(2018)]提出使用对抗性样本训练网络来主动攻击隐写分析方法。综合了几种不同的隐写分析方法，并对它们的隐写能力进行了实验验证。Hu等[Hu,Wang,Jiang等(2018)]提出将保密信息映射到噪声矢量作为生成器的输入，无需修改图像即可直接生成保密图像。算法分为三个步骤。1。利用有意义的噪声向量对GAN网络进行训练，使生成器能够直接生成cover图像。2. 隐藏图像作为输入器,和相应的网络与生成器作为提取网络训练隐藏图像的一维向量,以便恢复向量与原始输入尽可能一致的噪声向量,以提取秘密信息。提取器的损失函数如式(3)所示。生成器的参数提供给发送方，提取器的参数提供给接收方。该方法考虑了保密信息的提取部分，解决了利用GAN方法隐藏信息后提取保密信息的难题。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/396f16822255ca186bfba8afb62e0af5.png" alt=""></p>
<p>其中z为输入GAN的随机噪声，E (stego)为提取器回收的噪声向量。G(z)表示由噪声z生成器所生成的图像。Li等[Li, Jiang and Cheslyar(2018)]提出了利用GAN合成纹理图像作为秘密载体的方法。输入噪声被映射到从原始图像中选择的小块。网络可以生成不同的纹理，即使是相同的原始图像，这使得中间攻击者很难获得。将合成的纹理图像与秘密信息一起发送到另一个信息隐藏网络中，实现秘密通信。信息隐藏网络采用自编码网络结构，同时对秘密信息进行编码和解码。实验中使用了两个独立的数据集，一个用于纹理生成，另一个用于信息隐藏。当传输通道中存在潜在的隐写分析方法时，基于GAN的隐写方法可以通过降低特定隐写分析方法的检测率，有效地解决这一问题。通过隐写分析算法与GAN发生器的对抗，得到的隐写图像具有较高的安全性和较强的隐写分析抵抗能力。虽然该方法在一定程度上可以抵抗隐写分析，但是生成的隐写图像的视觉效果并不好，可以进一步提高反隐写分析能力。</p>
<h4 id="隐藏整个秘密图像的隐写算法"><a href="#隐藏整个秘密图像的隐写算法" class="headerlink" title="隐藏整个秘密图像的隐写算法"></a>隐藏整个秘密图像的隐写算法</h4><p>除了使用GAN模型隐藏秘密信息外，还有人提出将整个秘密图像隐藏到基于深度学习和自动编码的cover图像中，这样接收者就可以恢复秘密图像和cover图像。Baluja[Baluja(2017)]提出利用神经网络找到合适的位置将秘密信息嵌入到图像中。如图5所示，训练编码过程嵌入整个秘密图像来cover图像，使秘密信息可以分散在图像的每个位上。首先，利用预处理网络对秘密图像进行归一化，同时提取重要特征。然后通过隐藏网络对大小相同的秘密图像和cover图像进行编码，得到隐藏图像。同时，该模型还训练了与编码器相对应的解码器来提取秘密图像。它是解码的过程。虽然该方法可以实现对整个图像的隐藏，并实现对隐藏图像和秘密图像的双重恢复。然而，仍然存在一些问题。例如，将秘密图像隐藏在cover图像中之后，仍然可以看到隐藏的秘密图像。同时，该方法对隐写分析也不具有抵抗性。Rahim等人[Rahim and Nadeem(2017)]提出了另一种类似于这种方法的方法，该方法还结合了编解码器网络和CNN。实验结果表明，stego图像的图像质量非常好，但实验结果表明，stego图像的颜色与cover图像的颜色不同。整个网络的损失函数定义为式(4):</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/a4cc1f636125635c6f69fabae1643554.png" alt=""></p>
<p>其中I(cover)和I(secret)表示cover图像和secret图像的输入，O(stego)和O(recover)表示stego图像的输出和恢复图像。W(encode)和W(decode)表示的是编码器和解码器的权值。aα，β，λ为对应项的控制参数。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/c5dbd2c1662177bfae1c6234deba759f.png" alt=""></p>
<p>基于这两种方法，Zhang等[Zhang, Dong, Liu(2018)]提出将cover图像分为Y、U、V三个通道，通过编码器将灰度秘密图像隐藏到cover图像的Y通道中。然后，利用GAN模型的生成器，将cover图像的U、V通道与stego Y通道进行融合。鉴别器使用Xu等[Xu, Wu and Shi(2016)]的隐写分析网络进行抵抗。最后，生成stego图像。接收机通过解码器提取秘密图像。与以前的算法相比，该方法的效果有了很大的提高。stego图像和cover图像的颜色看起来和肉眼是一样的，残留增强的效果也是肉眼看不到的。算法效果图如图6所示，第一列为cover图像，第二列为秘密图像，第三列为stego图像，第四列为恢复秘密图像。</p>
<p>上述算法可以实现高容量的信息隐藏。这些方法的独特之处在于能够将整个图像隐藏在相同大小的cover图像中，并且能够恢复cover图像和秘密图像。因此，我们将它们分类为隐藏整个秘密图像的信息隐藏类。这种方法适用于高容量的保密信息传输或保密图像传输。这种方法的优点是，这些算法可以提高隐藏能力，可以在一个图像中隐藏一个秘密图像，而不是少量的比特信息。然而，这些方法由于嵌入率高、安全性差而无法抵抗隐写分析。</p>
<p>3.1.3选择嵌入位置等隐写算法</p>
<p>除上述两种方法外，还有其他使用深度学习模型进行信息隐藏的算法。Wu等[Wu, Wang andShi(2016)]利用机器学习方法实现了LSB的隐藏。Atee等[Atee, Ahmad, Noor等(2017)]提出了基于极限学习机(ELM)的学习方法，并选择了最优的嵌入信息位置。该方法能较好地保证图像的视觉效果，具有较好的不可感知性。Meng等[Meng,Rice, Wang et al.(2018)]提出使用更快的rcnn目标检测方法，找到用于信息隐藏的复杂目标区域，称为MSA_ROI。由于图像中可能存在多个对象，因此采用多种自适应隐写算法来隐藏不同对象区域的信息。该算法结构如图7所示，首先将cover图像作为输入图像，通过VGG提取图像特征。其次，特征映射通过局部建议网络获取建议。第三，考虑建议的分类和边界回归。最后，在不同的目标区域使用不同的自适应隐写算法进行区域隐写。虽然该方法可以在特定区域进行隐写，但不能对前景对象准确地隐藏秘密信息，降低了隐藏能力。该算法的效果如图8所示。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/319e8f2bf696e16bb9fd9ac38b9594ea.png" alt=""></p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/f4850bf4d687950c0e188c3138a32a27.png" alt=""></p>
<h3 id="基于深度学习的水印算法"><a href="#基于深度学习的水印算法" class="headerlink" title="基于深度学习的水印算法"></a>基于深度学习的水印算法</h3><p>深度学习网络的共享大大降低了工程师和研究人员的调试和训练负担，但模型篡改和版权损失等问题带来了安全风险。因此，如何保障深度学习网络的知识产权，如何保障研究者的权益，是深度学习推广应用中需要解决的问题。目前，该研究还处于起步阶段。Yalcin等[Yalcin and Vandewalle(2002)]提出了一种脆弱的水印技术和一种CNN-UM结构，可以用来生成添加到宿主图像中的伪随机噪声。Mun等[Mun, Nam,Jang等(2017)]提出了一种利用CNN模型实现盲水印的方法。如图9所示，该方法主要包括水印嵌入、仿真攻击和权值修改三个部分。首先，通过CNN将标记嵌入到输入图像中，得到标记图像。其次，对标记图像进行攻击仿真，攻击仿真包括JPEG压缩、降噪、高斯滤波、中值滤波等，最后得到攻击图像。最后，通过被攻击的标记继续攻击图像，从而不断更新权重。根据攻击类型，自适应地捕获更健壮的区域。与QDFT相比，该方法可以通过网络学习隐藏在特定的领域。Kandi等[Kandi,Mishra and Gorthi(2017)]提出了一种基于cnn的鲁棒非盲水印码本，优于变换域方法。此外，在深度神经网络模型保护方面，Uchida等[Uchida, Nagai,Sakazawa等(2017)]提出将数字水印嵌入训练好的神经网络模型中，以达到版权保护的目的。Li等[Li,Deng,Gupta等(2018)]提出了一种基于CNN的城市应用安全保证图像水印生成场景。Rouhani等人[Rouhani,Chen and Koushanfar(2018)]提出了深度指标。它是基于深度学习的系统水印和知识产权保护领域中一种新颖的端到端结构。算法的优点是它提出了深度指标,应用一组度量指标来评估水印嵌入方法对深度学习模型的效果等</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/a6ccb1958c655832eeb724d2eb9bdb6c.png" alt=""></p>
<h3 id="基于深度学习的无载体信息隐藏算法"><a href="#基于深度学习的无载体信息隐藏算法" class="headerlink" title="基于深度学习的无载体信息隐藏算法"></a>基于深度学习的无载体信息隐藏算法</h3><p>应用深度学习的无载体信息隐藏主要通过结合GAN和无载体信息隐藏。GAN可以根据一定的要求生成所需的图像。结合这些特点，无载体信息隐藏可以直接生成由秘密信息驱动的stego图像。从而增强了隐藏能力，提高了安全性。Liu等[Liu, Zhang Liu等(2017)]提出直接使用ACGAN生成器进行无载体信息隐藏。该方法通过建立图像类别与文本之间的映射字典，将机密信息划分为图像类别信息，并将其表示为图像类别信息。然后将图像类别信息输入生成器，生成作为stego图像的图像，从而实现无载体信息隐藏。为了保证GAN的安全性，Ke等[Ke,Zhang,Liu等(2017)]提出了一种满足Kerckhoffs原理的生成器，直接使用密钥和cover图像作为生成器在GAN中的输入，直接生成stego图像。Duan等[Duan,Song, Qin等(2018)]提出基于生成模型生成两幅视觉相同的图像。</p>
<h3 id="基于深度学习的隐写分析"><a href="#基于深度学习的隐写分析" class="headerlink" title="基于深度学习的隐写分析"></a>基于深度学习的隐写分析</h3><p>由于传统的隐写分析算法过程与CNN分类过程相对应，所以CNN模型在隐写分析中得到了广泛的应用。</p>
<p>在将深度学习应用于信息隐藏之前，Qian等[Qian, Dong,Wang等(2015)]在2015年提出了一个基于深度学习的隐写分析框架。该算法的结构如图10所示。该算法的主要目的是利用传统算法对图像进行高通滤波预处理，提高图像的噪声。预处理后的图像输入到CNN模型中进行图像特征提取。激活函数为高斯函数，如式(5)所示，只有当输入接近零时，激活函数才会有接近1的正反馈。最后，在全连通层对图像进行分类，使识别图像为cover图像或stego图像。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/1d400d9196090910b6a5ee017ea009d7.png" alt=""></p>
<p>其中σ用于确定曲线的宽度。只有当输入接近零时，激活函数才会有明显的正反馈。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/7e2d79da6c46f2c8e8a26520b167226a.png" alt=""></p>
<p>Zheng等[Zheng, Zhang, Wu et al.(2017)]提出了一种基于深度学习方法的隐写检测框架。通过对深度残差网络的训练，区分出cover图像和包含弱信号的stego图像。利用学习模型对图像进行特征提取，采用压缩层次聚类算法，根据图像与cover图像的最大距离求出stego图像。在这些方法之后，基于深度学习的隐写分析主要分为两类方法。<strong>一个方法是改善或改变网络模型结构,另一个是进一步增强模型的表达能力和泛化性能通过迁移学习和模型融合</strong>[Dong,Qian and Wang (2017)].</p>
<h4 id="改进或迁移网络模型结构的隐写分析方法"><a href="#改进或迁移网络模型结构的隐写分析方法" class="headerlink" title="改进或迁移网络模型结构的隐写分析方法"></a>改进或迁移网络模型结构的隐写分析方法</h4><p>在改进或改造网络模型结构的方法中，Xu等[Xu, Wu and Shi (2017)]提出一种基于CNN,隐写分析模型，它仍然使用Qian等人提出的高通滤波器[Qian,Dong, Wang等人(2015)]。但是，本文通过添加激活层(ABS)、批量归一化(BN)以及将一些激活函数修改为tanh激活函数，对CNN结构进行了改进。Salomon等[Salomon,Couturier, Guyeux等(2017)]提出了另一种基于CNN结构模型的隐写分析模型。与Qian et al.[Qian, Dong, Wang et al.(2015)]等人的网络模型相比，该模型只使用了两层卷积层，增加了每个卷积层的特征映射的数量。此外，由于考虑到池层的缩放操作是为了平滑噪声，不利于后续的隐写分析操作，因此删除池化层。对于JPEG隐写算法的检测，传统的方法依赖于JPEG特征的提取。然而，Chen等[Chen,Sedighi,Boroumand等(2017)]提出将JPEG相位感知转换为CNN网络的架构，从而提高检测器的检测精度。Xu等[2017]提出了一种基于20层CNN结构的J-UNIWARD[Holub, Fridrich and Denemark(2014)]检测方法，用于检测尺寸为256×256的BOSSBase数据集[Bas, fill and Pevny(2011)]和尺寸为512×512的CLS-LOC数据集。Tan等[Tan and Li(2014)]提出在训练前使用卷积自动编码器，多个卷积自动编码器组成一个CNN。目前，在改进模型结构的方法中，效果较好的是Ye等[Ye,Ni,Yi(2017)]提出的CNN结构改进模型。部分实验可达到99.9%的检测精度。该算法主要有<strong>四个改进</strong>:(1)使用SRM中的高通滤波内核初始化CNN卷积层第一层的权值，从而替代了随机初始化的方法;(2)定义新的截断线性单元，使网络能够很好地适应嵌入信号的分布(3)在输入stego图像时，结合所选通道;(4)对于低嵌入率的隐写分析，使用迁移学习策略。Wu等[Wu,Zhong,Liu(2017)]提出了共享标准化(SN)，用于在训练和测试过程中共享统计量。该方法能有效地捕获图像中的弱信号，从而训练出有效的网络。对于转换网络模型结构，Wu等[Wu,Zhong and Liu(2016)]使用本文中的深度残差网络进行隐写分析。在DNA隐写分析中，Bae等[Bae, Lee,Kwon et al.(2017)]主要通过提取循环神经网络(RNNs)组成的隐藏层，利用深度递归神经网络来模拟DNA序列的内部结构。在改进CNN模型使其适合隐写分析的方法中，仍有许多算法被提出[Yedroudj,Comby and Chaumont (2018); Ma, Guan, Zhao et al. (2018); Yang, Shi, Wong et al.(2017); Zhang, Zhu and Liu (2018)].</p>
<h4 id="基于迁移学习的隐写分析方法"><a href="#基于迁移学习的隐写分析方法" class="headerlink" title="基于迁移学习的隐写分析方法"></a>基于迁移学习的隐写分析方法</h4><p>为了通过迁移学习、模型融合等方法进一步提高模型的表达能力，Qian等[Qian, Dong,Wang等(2016)]提出了一种基于迁移学习的新框架来提高CNN模型的特征学习能力。该模型首先利用高有效载荷和相应覆盖率组成的训练图像对CNN模型进行预训练，然后将学习到的特征表示转化为正则化的CNN模型，更好地检测隐藏的低有效载荷。这样，可以有效地利用高负载隐藏的辅助信息来帮助检测低负载的隐藏任务。基于富模型隐写分析(SRM)的领域知识[Kodovsky and Fridrich (2013)]; Zeng等[Zeng, Tan, Li et al.(2018)]提出了一种用于混合深度学习的通用JPEG隐写分析框架。作者提出的框架主要包括两个阶段:第一阶段是制造阶段，对应于SRM的卷积阶段和量化截断阶段;第二阶段是一个复合深度神经网络，在训练过程中学习模型参数。Xu等[Xu,Wu and Shi(2016)]提出了一种基于正则化CNN的隐写分析模型。它利用传统人工设计特征的先验信息(如SRM、maxSRM [Denemark, Sedighi, Holub et al.(2014)]等)对CNN模型进行正则化，减少CNN训练中的过拟合问题，从而提高模型的隐写分析性能。在传统的隐写分析特征中，卷积网络结构难以获得有效的全局统计信息。因此，本文提出将这类信息通过模型正则化训练到CNN网络中，从而促进CNN学习更有效的隐写分析特征表达。在基于深度学习的隐写分析方法中，这种方法在传统的信息隐藏方法中具有更好的检测能力，在基于深度学习的隐写算法中也能很好地检测出隐写图像。这给隐写术带来了一些挑战。</p>
<h2 id="评估与比较"><a href="#评估与比较" class="headerlink" title="评估与比较"></a>评估与比较</h2><hr>
<p>本节的重点是在量化一些变量的情况下，算法性能的比较和分析。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/163be0e29f26ee47786a70350056ec3b.png" alt=""></p>
<p>在表1中，使用相同隐写分析方法比较用SGAN和SSGAN的检测精度和训练时间消耗。显然，SSGAN在较低的检测率下抵抗探测器检测方面更有效。</p>
<p>表2展示了在采用SRM隐写分析算法的情况下，三种相关隐写算法对隐写分析的反检测性能。结果表明，S-UNIWARD的实验结果对实验结果的掩盖作用最大。然而，基于GAN的方法在特征学习方面的优势显示了它们的发展潜力。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/664228982c0eaee070dea74eaf4d7439.png" alt=""></p>
<p>表3给出了PSNR值的对比差别。stego图像与cover图像之间的最大值反映了ISGAN实现的图像的最佳质量。而对于恢复的秘密图像和原始的秘密图像，则通过ENDS获得最佳的质量。实验表明，该算法在鲁棒性和隐蔽性之间达到了平衡。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/68ff4a110ca801c7cee5d4b5285bfeaf.png" alt=""></p>
<p>如表4所示，我们将本文的实验数据转换为统一的标准，即逐像素位(bit-per-pixel,bpp)。在此量下，算法[Ke, Zhang, Liu et al.(2017)]的隐藏能力优于算法[Liu, Zhang,Liu et al.(2017)]。</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/7935eb3e48bd424e58a0d432f78f4d21.png" alt=""></p>
<p>无噪声和有攻击水印图像的PSNR值比较如表5和表6所示。在这个量下，我们发现Kandi等人[Kandi,Mishra and Gorthi(2017)]的PSNR平均值最高，没有受到任何攻击。然而，Mun等[Mun,Nam, Jang et al.(2017)]的反攻击方法优于Kandi等[Kandi, Mishra and Gorthi (2017)].</p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/a2e3c535da76ae4fea15904ddaa292ec.png" alt=""></p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/7b185cdfae1e9dc9619aba77d6c1dcef.png" alt=""></p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/dcc81efa1910402f75558d68e76cfa04.png" alt=""></p>
<p><img src="/2019/09/29/A-Survey-of-Image-Information-Hiding-Algorithms-Based-on-DeepLearning-2018-CR3/b1d80a8c874f0822db04ce92e3cf731a.png" alt=""></p>
<p>表7表示基于隐写术的不同深度学习算法对不同隐写术算法的性能。对于使用0.1bpp的S-UNIWARD隐写算法的情况，Ye等[Ye, Ni and Yi(2017)]提出的隐写分析算法检测效果最好，检测误差最小，为0.3220。当S-UNIWARD有效载荷为0.4bpp时，Wu等[Wu, Zhong and Liu (2016); Zheng, Zhang, Wu et al.(2017)]的研究表现出较好的实验结果，分别为0.0630和0.0000。同时，Wu等[Wu, Zhong,Liu(2016)]的隐写分析方法在检测HUGO和WOW获得的0.4bpp的隐写图像时，检测误差分别为0.0410和0.0430。Ye等人[Ye, Ni,Yi(2017)]提出的隐写分析方法在使用WOW隐写算法对隐写图像进行隐写分析时，具有更好的实验结果。</p>
<h2 id="结论与未来工作"><a href="#结论与未来工作" class="headerlink" title="结论与未来工作"></a>结论与未来工作</h2><p>本文从隐写、水印、无载体信息隐藏和隐写分析四个方面对基于深度学习的图像信息隐藏算法进行了描述和分析。在这些领域，虽然已经做了一些研究，但仍有一些问题需要进一步完善。例如，一些基于隐写的算法具有较强的鲁棒性，但相应的提取方法还有待改进。此外，还可以通过引入新的适合于信息隐藏算法的优化函数、添加或使用适合该算法的深度学习模型对现有算法进行进一步优化。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>Al-Ataby, A.; Al-Naima, F. (2008): A modified high capacity image steganography</p>
<p>technique based on wavelet transform. Changes, vol. 4, pp. 6.</p>
<p>Akkus, Z.; Galimzianova, A.; Hoogi, A.; Rubin, D. L.; Erickson, B. J. (2017):<br>Deep</p>
<p>learning for brain MRI segmentation: State of the art and future directions.<br>Journal of</p>
<p>Digital Imaging, vol. 30, no. 4, pp. 449-459.</p>
<p>Arik, S. O.; Chen, J.; Peng, K.; Ping, W.; Zhou, Y. (2018): Neural voice cloning<br>with</p>
<p>a few samples. Computation and Language.</p>
<p>Arjovsky, M.; Chintala, S.; Bottou, L. (2017): Wasserstein GAN. Machine<br>Learning.</p>
<p>Atee, H. A.; Ahmad, R.; Noor, N. M.; Rahma, A. M. S.; Aljeroudi, Y. (2017):</p>
<p>Extreme learning machine based optimal embedding location finder for image</p>
<p>steganography. Plos One, vol. 12, no. 2.</p>
<p>Bae, H.; Lee, B.; Kwon, S.; Yoon, S. (2017): DNA steganalysis using deep<br>recurrent</p>
<p>neural networks. Machine Learning.</p>
<p>Barz, B.; Denzler, J. (2018): Hierarchy-based image embeddings for semantic<br>image</p>
<p>retrieval. Computer Vision and Pattern Recognition.</p>
<p>Bas, P.; Filler, T.; Pevný, T. (2011): “Break our steganographic system”: The<br>ins and</p>
<p>outs of organizing BOSS. International Workshop on Information Hiding, pp.<br>59-70.</p>
<p>Baluja, S. (2017): Hiding images in plain sight: Deep steganography. Advances in</p>
<p>Neural Information Processing Systems, pp. 2069-2079.</p>
<p>Brock, A.; Donahue, J.; Simonyan, K. (2018): Large scale GAN training for high</p>
<p>fidelity natural image synthesis. Machine Learning.</p>
<p>Chang, C. C.; Fan, Y. H.; Tai, W. L. (2008): Four-scanning attack on<br>hierarchical</p>
<p>digital watermarking method for image tamper detection and recovery. Pattern</p>
<p>Recognition, vol. 41, no.2, pp. 654-661.</p>
<p>Che, T.; Li, Y.; Jacob, A. P.; Bengio, Y.; Li, W. (2016): Mode regularized<br>generative</p>
<p>adversarial networks. Machine Learning.</p>
<p>Che, T.; Li, Y.; Zhang, R.; Hjelm, R. D.; Li, W. et al. (2017):<br>Maximum-likelihood</p>
<p>augmented discrete generative adversarial networks. Artificial Intelligence.</p>
<p>Chen, B.; Wornell, G. W. (2001): Quantization index modulation: A class of<br>provably</p>
<p>good methods for digital watermarking and information embedding. IEEE<br>Transactions</p>
<p>on Information Theory, vol. 47, no. 4, pp. 1423-1443.</p>
<p>Chen, C.; Shi, Y. Q. (2008): JPEG image steganalysis utilizing both intrablock<br>and</p>
<p>interblock correlations. IEEE International Symposium on Circuits and Systems,<br>pp.</p>
<p>3029-3032.</p>
<p>Chen, M.; Sedighi, V.; Boroumand, M.; Fridrich, J. (2017): JPEG-phase-aware</p>
<p>convolutional neural network for steganalysis of JPEG images. Proceedings of the<br>5th</p>
<p>ACM Workshop on Information Hiding and Multimedia Security, pp. 75-84.</p>
<p>Chen, P. Y.; Lin, H. J. (2006): A DWT based approach for image steganography.</p>
<p>International Journal of Applied Science and Engineering, vol. 4, no. 3, pp.<br>275-290.</p>
<p>Cui, Q.; McIntosh, S.; Sun, H. (2018): Identifying materials of photographic<br>images</p>
<p>and photorealistic computer generated graphics based on deep CNNs. Computers,</p>
<p>Materials &amp; Continua, vol. 55, no. 2, pp. 229-241.</p>
<p>Dai, J.; Li, Y.; He, K.; Sun, J. (2016): R-FCN: object detection via<br>region-based fully</p>
<p>convolutional networks. Advances in Neural Information Processing Systems, pp.<br>379-387.</p>
<p>Denemark, T.; Boroumand, M.; Fridrich, J. (2016): Steganalysis features for<br>content-</p>
<p>adaptive JPEG steganography. IEEE Transactions on Information Forensics and</p>
<p>Security, vol. 11, no. 8, pp. 1736-1746.</p>
<p>Denemark, T.; Fridrich, J.; Comesaña-Alfaro, P. (2016): Improving<br>selectionchannel-aware steganalysis features. Electronic Imaging, vol. 2016, no.<br>8, pp. 1-8.</p>
<p>Denemark, T.; Fridrich, J.; Holub, V. (2014): Further study on the security of<br>SUNIWARD. International Society for Optics and Photonics on Media Watermarking,</p>
<p>Security, and Forensics, vol. 9028.</p>
<p>Denemark, T.; Sedighi, V.; Holub, V.; Cogranne, R.; Fridrich, J. (2014):<br>Selectionchannel-aware rich model for steganalysis of digital images. IEEE<br>International</p>
<p>Workshop on Information Forensics and Security, pp. 48-53.</p>
<p>Deng, C.; Gao, X.; Li, X.; Tao, D. (2009): A local Tchebichef moments-based<br>robust</p>
<p>image watermarking. Signal Process, vol. 89, no. 8, pp. 1531-1539.</p>
<p>Dong, J.; Qian, Y.; Wang, W. (2017): Recent advances in image steganalysis.<br>Journal</p>
<p>of Image and Signal Processing, vol. 6, no. 3, pp. 131-138.</p>
<p>Dorairangaswamy, M. A. (2009): A novel invisible and blind watermarking scheme<br>for</p>
<p>copyright protection of digital images. International Journal of Computer<br>Science and</p>
<p>Network Security, vol. 9, no. 4, pp. 71-78.</p>
<p>Duan, L.; Lou, Y.; Wang, S.; Gao, W.; Rui, Y. (2017): AI oriented large-scale<br>video</p>
<p>management for smart city: Technologies, standards and beyond. IEEE MultiMedia,<br>pp. 1.</p>
<p>Duan, X.; Song, H. (2018): Coverless information hiding based on generative<br>model.</p>
<p>Computer Vision and Pattern Recognition.</p>
<p>Duan, X.; Song, H.; Qin, C.; Khan, M. K. (2018): Coverless steganography for<br>digital</p>
<p>images based on a generative model. Computers, Materials &amp; Continua, vol. 55,<br>no. 3,</p>
<p>pp. 483-493.</p>
<p>Dutta, S.; Murthy, A. R.; Kim, D.; Samui, P. (2017): Prediction of compressive</p>
<p>strength of self-compacting concrete using intelligent computational modeling.</p>
<p>Computers, Materials &amp; Continua, vol. 53, no. 2, pp. 157-174.</p>
<p>Eggers, J. J.; Girod, B. (2001): Blind watermarking applied to image<br>authentication.</p>
<p>IEEE International Conference on Acoustics, Speech, and Signal Processing, vol.<br>3, pp.</p>
<p>1977-1980.</p>
<p>Feichtenhofer, C.; Fan, H.; Malik, J.; He, K. (2018): SlowFast networks for<br>video</p>
<p>recognition. Computer Vision and Pattern Recognition.</p>
<p>Fridrich, J. (1999): Protection of digital images using self-embedding.<br>Symposium on</p>
<p>Content Security and Data Hiding in Digital Media, New Jersey Institute of<br>Technology.</p>
<p>Fridrich, J.; Kodovsky, J. (2012): Rich models for steganalysis of digital<br>images. IEEE</p>
<p>Transactions on Information Forensics and Security, vol. 7, no. 3, pp. 868-882.</p>
<p>Fu, H.; Gong, M.; Wang, C.; Batmanghelich, K.; Tao, D. (2018): Deep ordinal</p>
<p>regression network for monocular depth estimation. Proceedings of the IEEE<br>Conference</p>
<p>on Computer Vision and Pattern Recognition, pp. 2002-2011.</p>
<p>Gautam, C.; Tiwari, A.; Leng, Q. (2017): On the construction of extreme learning</p>
<p>machine for online and offline one-class classification-an expanded toolbox.</p>
<p>Neurocomputing, vol. 261, pp. 126-143.</p>
<p>Goldberg, Y.; Levy, O. (2014): Word2vec explained: deriving Mikolov et al.’s<br>negativesampling word-embedding method. Computation and Language.</p>
<p>Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley, D. et al.<br>(2014):</p>
<p>Generative adversarial nets. Advances in Neural Information Processing Systems,<br>pp.</p>
<p>2672-2680.</p>
<p>Gunjal, B. L.; Mali, S. N. (2015): MEO based secured, robust, high capacity and</p>
<p>perceptual quality image watermarking in DWT-SVD domain. Springer Plus, vol. 4,<br>no.</p>
<p>1, pp. 126.</p>
<p>Gurusamy, R.; Subramaniam, V. (2017): A machine learning approach for MRI brain</p>
<p>tumor classification. Computers, Materials &amp; Continua, vol. 53 no. 2, pp.<br>91-108.</p>
<p>Hayes, J.; Danezis, G. (2017): Generating steganographic images via adversarial</p>
<p>training. Advances in Neural Information Processing Systems, pp. 1954-1963.</p>
<p>He, H.; Chen, F.; Tai, H.; M.; Kalker, T.; Zhang, J. (2012): Performance<br>analysis of a</p>
<p>block-neighborhood-based self-recovery fragile watermarking scheme. IEEE<br>Transactions</p>
<p>on Information Forensics and Security, vol. 7, no. 1, pp. 185-196.</p>
<p>He, H. J.; Zhang, J. S.; Tai, H. M. (2009): Self-recovery fragile watermarking<br>using</p>
<p>block-neighborhood tampering characterization. International Workshop on<br>Information</p>
<p>Hiding, pp. 132-145.</p>
<p>He, K.; Zhang, X.; Ren, S.; Sun, J. (2016): Deep residual learning for image</p>
<p>recognition. Proceedings of the IEEE Conference on Computer Vision and Pattern</p>
<p>Recognition, pp. 770-778.</p>
<p>Hinton, G. E.; Salakhutdinov, R. R. (2006): Reducing the dimensionality of data<br>with</p>
<p>neural networks. Science, vol. 313, no. 5786, pp. 504-507.</p>
<p>Hjelm, R. D.; Jacob, A. P.; Che, T.; Trischler, A.; Cho, K. et al. (2017):<br>Boundaryseeking generative adversarial networks. Machine Learning.</p>
<p>Holub, V.; Fridrich, J. (2012): Designing steganographic distortion using<br>directional</p>
<p>filters. IEEE International Workshop on Information Forensics and Security, vol.<br>2, no. 4,</p>
<p>pp. 234-239.</p>
<p>Holub, V.; Fridrich, J. (2013): Random projections of residuals for digital<br>image</p>
<p>steganalysis. IEEE Transactions on Information Forensics and Security, vol. 8,<br>no. 12, pp.</p>
<p>1996-2006.</p>
<p>Holub, V.; Fridrich, J. (2015a): Low-complexity features for JPEG steganalysis<br>using</p>
<p>undecimated DCT. IEEE Transactions on Information Forensics and Security, vol.<br>10,</p>
<p>no. 2, pp. 219-228.</p>
<p>Holub, V.; Fridrich, J. (2015b): Phase-aware projection model for steganalysis<br>of JPEG</p>
<p>images. International Society for Optics and Photonics on Media Watermarking,<br>Security,</p>
<p>and Forensics, vol. 9409.</p>
<p>Holub, V.; Fridrich, J.; Denemark, T. (2014): Universal distortion function for</p>
<p>steganography in an arbitrary domain. EURASIP Journal on Information Security,<br>vol.</p>
<p>2014, no. 1, pp. 1.</p>
<p>Hu, D.; Wang, L.; Jiang, W.; Zheng, S.; Li, B. (2018): A novel image<br>steganography</p>
<p>method via deep convolutional generative adversarial networks. IEEE Access, vol.<br>6, pp.</p>
<p>38303-38314.</p>
<p>Jaeger, P. F.; Kohl, S. A.; Bickelhaupt, S.; Isensee, F.; Kuder, T. A. et al.<br>(2018):</p>
<p>Retina U-Net: Embarrassingly simple exploitation of segmentation supervision for</p>
<p>medical object detection. Computer Vision and Pattern Recognition.</p>
<p>Johnson, N.; Jajodia, S. (1998): Exploring steganography: Seeing the unseen.<br>Computer,</p>
<p>vol. 31, pp. 2634.</p>
<p>Kandi, H.; Mishra, D.; Gorthi, S. R. S. (2017): Exploring the learning<br>capabilities of</p>
<p>convolutional neural networks for robust image watermarking. Computers &amp;<br>Security,</p>
<p>vol. 65, pp. 247-268.</p>
<p>Kang, S. I.; Lee, I. Y. (2006): A study on the electronic voting system using<br>blind</p>
<p>signature for anonymity. International Conference on Hybrid Information<br>Technology,</p>
<p>vol. 2, pp. 660-663.</p>
<p>Karras, T.; Laine, S.; Aila, T. (2018): A style-based generator architecture for</p>
<p>generative adversarial networks. Neural and Evolutionary Computing.</p>
<p>Ke, Y.; Zhang, M.; Liu, J.; Su, T. (2017): Generative steganography with<br>kerckhoffs’</p>
<p>principle based on generative adversarial networks. Multimedia.</p>
<p>Kim, T.; Cha, M.; Kim, H.; Lee, J. K.; Kim, J. (2017): Learning to discover<br>cross-domain</p>
<p>relations with generative adversarial networks. Computer Vision and Pattern<br>Recognition.</p>
<p>Kingma, D. P.; Welling, M. (2013): Auto-encoding variational bayes. Machine<br>Learning.</p>
<p>Kodovský, J.; Fridrich, J. (2011): Steganalysis in high dimensions: Fusing<br>classifiers</p>
<p>built on random subspaces. International Society for Optics and Photonics on<br>Media</p>
<p>Watermarking, Security, and Forensics, vol. 7880.</p>
<p>Kodovský, J.; Fridrich, J. (2012): Steganalysis of JPEG images using rich<br>models.</p>
<p>International Society for Optics and Photonics on Media Watermarking, Security,<br>and</p>
<p>Forensics, vol. 8303</p>
<p>Kodovský, J.; Fridrich, J. (2013): Quantitative steganalysis using rich models.</p>
<p>International Society for Optics and Photonics on Media Watermarking, Security,<br>and</p>
<p>Forensics, vol. 8665.</p>
<p>Kodovský, J.; Fridrich, J.; Holub, V. (2012): Ensemble classifiers for<br>steganalysis of</p>
<p>digital media. IEEE Transactions on Information Forensics and Security, vol. 7,<br>no. 2, pp.</p>
<p>432-444.</p>
<p>Li, C.; Jiang, Y.; Cheslyar, M. (2018): Embedding image through generated</p>
<p>intermediate medium using deep convolutional generative adversarial network.</p>
<p>Computers, Materials &amp; Continua, vol. 56, no. 2, pp. 313-324.</p>
<p>Li, Z.; Chen, X.; Pan, X.; Zeng, X. (2009): Lossless data hiding scheme based on</p>
<p>adjacent pixel difference. International Conference on Computer Engineering and</p>
<p>Technology, vol. 1, pp. 588-592.</p>
<p>Li, D.; Deng, L.; Gupta, B. B.; Wang, H.; Choi, C. (2018): A novel CNN based</p>
<p>security guaranteed image watermarking generation scenario for smart city<br>applications.</p>
<p>Information Sciences. <a href="https://doi.org/10.1016/j.ins.2018.02.060" target="_blank" rel="noopener">https://doi.org/10.1016/j.ins.2018.02.060</a>.</p>
<p>Liang, Z.; Jiang, K.; Chen, H.; Zhu, J.; Li, Y. (2018): Deep reinforcement<br>learning in</p>
<p>portfolio management. Portfolio Management.</p>
<p>Liu, M. M.; Zhang, M. Q.; Liu, J.; Zhang, Y. N.; Ke, Y. (2017): Coverless<br>information</p>
<p>hiding based on generative adversarial networks. Cryptography and Security.</p>
<p>Liu, N.; Zhang, Y.; Chen, Z.; Zhang, S. (2009): Chaos-based semi-blind<br>watermarking</p>
<p>for CAD models. WRI Global Congress on Intelligent Systems, vol. 3, pp. 411-414.</p>
<p>Liu, W.; Anguelov, D.; Erhan, D.; Szegedy, C.; Reed, S. et al. (2016): SSD:<br>Single</p>
<p>shot multibox detector. European Conference on Computer Vision, pp. 21-37.</p>
<p>Liu, Z.; Luo, P.; Wang, X.; Tang, X. (2015): Deep learning face attributes in<br>the wild.</p>
<p>Proceedings of the IEEE International Conference on Computer Vision, pp.<br>3730-3738.</p>
<p>Le, H.; Pham, Q.; Sahoo, D.; Hoi, S. C. (2018): URLNet: Learning a url<br>representation</p>
<p>with deep learning for malicious URL detection. Cryptography and Security.</p>
<p>Long, Y.; Liu, Y. (2018): Text coverless information hiding based on word2vec.</p>
<p>International Conference on Cloud Computing and Security, pp. 463-472.</p>
<p>Ma, S.; Guan, Q.; Zhao, X.; Liu, Y. (2018): Weakening the detecting capability<br>of</p>
<p>CNN-based steganalysis. Multimedia.</p>
<p>Ma, S.; Guan, Q.; Zhao, X.; Liu, Y. (2018): Adaptive spatial steganography based<br>on</p>
<p>probability-controlled adversarial examples. Multimedia.</p>
<p>Mao, X.; Li, Q.; Xie, H.; Lau, R. Y.; Wang, Z. et al. (2017): Least squares<br>generative</p>
<p>adversarial networks. IEEE International Conference on Computer Vision, pp.<br>2813-2821.</p>
<p>Meng, R.; Rice, S. G.; Wang, J.; Sun, X. (2018): A fusion steganographic<br>algorithm</p>
<p>based on faster R-CNN. Computers, Materials &amp; Continua, vol. 55, no. 1, pp.<br>1-16.</p>
<p>Mielikainen, J. (2006): LSB matching revisited. IEEE Signal Processing Letters,<br>vol. 13,</p>
<p>pp. 285-287.</p>
<p>Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Veness, J. et al. (2015):<br>Humanlevel control through deep reinforcement learning. Nature, vol. 518, no.<br>7540, pp. 529.</p>
<p>Mobadersany, P.; Yousefi, S.; Amgad, M.; Gutman, D. A.; Barnholtz-Sloan, J. S.<br>et</p>
<p>al. (2018): Predicting cancer outcomes from histology and genomics using<br>convolutional</p>
<p>networks. Proceedings of the National Academy of Sciences, vol.115, no. 13, pp.<br>E2970-</p>
<p>E2979.</p>
<p>Montavon, G.; Müller, K. R. (2012): Deep Boltzmann machines and the centering<br>trick.</p>
<p>Neural Networks: Tricks of the Trade, pp. 621-637.</p>
<p>Mun, S. M.; Nam, S. H.; Jang, H. U.; Kim, D.; Lee, H. K. (2017): A robust blind</p>
<p>watermarking using convolutional neural network. Multimedia.</p>
<p>Nazari, M.; Sharif, A.; Mollaeefar, M. (2017): An improved method for digital<br>image</p>
<p>fragile watermarking based on chaotic maps. Multimedia Tools and Applications,<br>vol. 76,</p>
<p>no. 15, pp. 16107-16123.</p>
<p>Nguyen, B. C.; Yoon, S. M.; Lee, H. K. (2006): Multi bit plane image<br>steganography.</p>
<p>International Workshop on Digital Watermarking, pp. 61-70.</p>
<p>Pevný, T.; Filler, T.; Bas, P. (2010): Using high-dimensional image models to<br>perform</p>
<p>highly undetectable steganography. Lecture Notes in Computer Science, vol. 6387,<br>pp.</p>
<p>161-177.</p>
<p>Pevný, T.; Fridrich, J. (2007): Merging Markov and DCT features for multi-class<br>JPEG</p>
<p>steganalysis. International Society for Optics and Photonics on Security,<br>Steganography,</p>
<p>and Watermarking of Multimedia Contents, vol. 6505.</p>
<p>Provos, N.; Honeyman, P. (2001): Detecting steganographic content on the<br>internet.</p>
<p>Chemia Analityczna, vol. 46, no. 4, pp. 569-577.</p>
<p>Provos, N.; Honeyman, P. (2003): Hide and seek: An introduction to<br>steganography.</p>
<p>IEEE Security &amp; Privacy, vol. 99, no. 3, pp. 32-44.</p>
<p>Qian, J.; Du, H.; Hou, J.; Chen, L.; Jung, T. et al. (2017): VoiceMask:<br>Anonymize</p>
<p>and sanitize voice input on mobile devices. Cryptography and Security.</p>
<p>Qian, Y.; Dong, J.; Wang, W.; Tan, T. (2015): Deep learning for steganalysis via</p>
<p>convolutional neural networks. Media Watermarking, Security, and Forensics,</p>
<p>International Society for Optics and Photonics, vol. 9409.</p>
<p>Qian, Y.; Dong, J.; Wang, W.; Tan, T. (2016): Learning and transferring</p>
<p>representations for image steganalysis using convolutional neural network. IEEE</p>
<p>International Conference on Image Processing, pp. 2752-2756.</p>
<p>Qin, Y.; Kamnitsas, K.; Ancha, S.; Nanavati, J.; Cottrell, G. et al. (2018):<br>Autofocus</p>
<p>layer for semantic segmentation. Computer Vision and Pattern Recognition.</p>
<p>Radford, A.; Metz, L.; Chintala, S. (2015): Unsupervised representation learning<br>with</p>
<p>deep convolutional generative adversarial networks. Machine Learning.</p>
<p>Rahim, R.; Nadeem, M. S. (2017): End-to-end trained CNN encode-decoder networks</p>
<p>for image steganography. Computer Vision and Pattern Recognition.</p>
<p>Rahman, M. M.; Ahammed, M. S.; Ahmed, M. R.; Izhar, M. N. (2017): A semi blind</p>
<p>watermarking technique for copyright protection of image based on DCT and SVD</p>
<p>domain. Global Journal of Research in Engineering, vol. 16, no. 7-F.</p>
<p>Rajpurkar, P.; Irvin, J.; Zhu, K.; Yang, B.; Mehta, H. et al. (2017): Chexnet:</p>
<p>Radiologist-level pneumonia detection on chest x-rays with deep learning.<br>Computer</p>
<p>Vision and Pattern Recognition.</p>
<p>Redmon, J.; Divvala, S.; Girshick, R.; Farhadi, A. (2016): You only look once:</p>
<p>Unified, real-time object detection. Proceedings of the IEEE Conference on<br>Computer</p>
<p>Vision and Pattern Recognition, pp. 779-788.</p>
<p>Ren, S.; He, K.; Girshick, R.; Sun, J. (2015): Faster R-CNN: Towards real-time<br>object</p>
<p>detection with region proposal networks. Advances in Neural Information<br>Processing</p>
<p>Systems, pp. 91-99.</p>
<p>Roddick, T.; Kendall, A.; Cipolla, R. (2018): Orthographic feature transform for</p>
<p>monocular 3D object detection. Computer Vision and Pattern Recognition.</p>
<p>Rouhani, B. D.; Chen, H.; Koushanfar, F. (2018): Deepsigns: A generic<br>watermarking</p>
<p>framework for IP protection of deep learning models. Cryptography and Security.</p>
<p>Ronneberger, O.; Fischer, P.; Brox, T. (2015): U-net: Convolutional networks for</p>
<p>biomedical image segmentation. International Conference on Medical Image<br>Computing</p>
<p>and Computer-Assisted Intervention, vol. 9351, pp. 234-241.</p>
<p>Russakovsky, O.; Deng, J.; Su, H.; Krause, J.; Fei-Fei, L. (2014): Imagenet<br>large scale</p>
<p>visual recognition challenge. International Journal of Computer Vision, vol.<br>115, pp. 3.</p>
<p>Sak, H.; Senior, A.; Beaufays, F. (2014): Long short-term memory recurrent<br>neural</p>
<p>network architectures for large scale acoustic modeling. Fifteenth Annual<br>Conference of</p>
<p>the International Speech Communication Association, pp. 338-342.</p>
<p>Sallee, P. (2003): Model-based steganography. International Workshop on Digital</p>
<p>Watermarking, pp. 154-167.</p>
<p>Salomon, M.; Couturier, R.; Guyeux, C.; Couchot, J. F.; Bahi, J. M. (2017):</p>
<p>Steganalysis via a convolutional neural network using large convolution filters<br>for</p>
<p>embedding process with same stego key: A deep learning approach for<br>telemedicine.</p>
<p>European Research in Telemedicine, vol. 6, no. 2, pp. 79-92.</p>
<p>Sanh, V.; Wolf, T.; Ruder, S. (2018): A hierarchical multi-task approach for<br>learning</p>
<p>embeddings from semantic tasks. Computation and Language.</p>
<p>Shi, H.; Dong, J.; Wang, W.; Qian, Y.; Zhang, X. (2017): SSGAN: secure</p>
<p>steganography based on generative adversarial networks. Pacific Rim Conference<br>on</p>
<p>Multimedia, pp. 534-544.</p>
<p>Simonyan, K.; Zisserman, A. (2014): Very deep convolutional networks for<br>large-scale</p>
<p>image recognition. Computer Vision and Pattern Recognition.</p>
<p>Talele, D. S. G. K.; Keskar, D. A. (2010): Steganography security for copyright</p>
<p>protection of digital images using DWT. International Journal of Computer and<br>Network</p>
<p>Security, vol. 2, pp. 4.</p>
<p>Tan, S.; Li, B. (2014): Stacked convolutional auto-encoders for steganalysis of<br>digital</p>
<p>images. Signal and Information Processing Association Annual Summit and<br>Conference,</p>
<p>pp. 1-4.</p>
<p>Tang, W.; Tan, S.; Li, B.; Huang, J. (2017): Automatic steganographic distortion</p>
<p>learning using a generative adversarial network. IEEE Signal Processing Letters,<br>vol. 24,</p>
<p>no. 10, pp. 1547-1551.</p>
<p>Uchida, Y.; Nagai, Y.; Sakazawa, S.; Satoh, S. I. (2017): Embedding watermarks<br>into</p>
<p>deep neural networks. Proceedings of the 2017 ACM on International Conference on</p>
<p>Multimedia Retrieval, pp. 269-277.</p>
<p>Volkhonskiy, D.; Nazarov, I.; Borisenko, B.; Burnaev, E. (2017): Steganographic</p>
<p>generative adversarial networks. Multimedia.</p>
<p>Wang, T. C.; Liu, M. Y.; Zhu, J. Y.; Liu, G.; Tao, A. et al. (2018):<br>Video-to-video</p>
<p>synthesis. Computer Vision and Pattern Recognition.</p>
<p>Wang, Q.; Chan, A. B. (2018): CNN+CNN: Convolutional decoders for image</p>
<p>captioning. Computer Vision and Pattern Recognition.</p>
<p>Westfeld, A. (2001): F5-A steganographic algorithm. Information Hiding: 4th</p>
<p>International Workshop, vol. 2137, pp. 289.</p>
<p>Wichers, N.; Villegas, R.; Erhan, D.; Lee, H. (2018): Hierarchical long-term<br>video</p>
<p>prediction without supervision. International Conference on Machine Learning.</p>
<p>Wu, H. Z.; Wang, H. X.; Shi, Y. Q. (2016): Can machine learn steganography?-</p>
<p>Russakovsky, O.; Deng, J.; Su, H.; Krause, J.; Fei-Fei, L. (2014): Imagenet<br>large scale</p>
<p>visual recognition challenge. International Journal of Computer Vision, vol.<br>115, pp. 3.</p>
<p>Sak, H.; Senior, A.; Beaufays, F. (2014): Long short-term memory recurrent<br>neural</p>
<p>network architectures for large scale acoustic modeling. Fifteenth Annual<br>Conference of</p>
<p>the International Speech Communication Association, pp. 338-342.</p>
<p>Sallee, P. (2003): Model-based steganography. International Workshop on Digital</p>
<p>Watermarking, pp. 154-167.</p>
<p>Salomon, M.; Couturier, R.; Guyeux, C.; Couchot, J. F.; Bahi, J. M. (2017):</p>
<p>Steganalysis via a convolutional neural network using large convolution filters<br>for</p>
<p>embedding process with same stego key: A deep learning approach for<br>telemedicine.</p>
<p>European Research in Telemedicine, vol. 6, no. 2, pp. 79-92.</p>
<p>Sanh, V.; Wolf, T.; Ruder, S. (2018): A hierarchical multi-task approach for<br>learning</p>
<p>embeddings from semantic tasks. Computation and Language.</p>
<p>Shi, H.; Dong, J.; Wang, W.; Qian, Y.; Zhang, X. (2017): SSGAN: secure</p>
<p>steganography based on generative adversarial networks. Pacific Rim Conference<br>on</p>
<p>Multimedia, pp. 534-544.</p>
<p>Simonyan, K.; Zisserman, A. (2014): Very deep convolutional networks for<br>large-scale</p>
<p>image recognition. Computer Vision and Pattern Recognition.</p>
<p>Talele, D. S. G. K.; Keskar, D. A. (2010): Steganography security for copyright</p>
<p>protection of digital images using DWT. International Journal of Computer and<br>Network</p>
<p>Security, vol. 2, pp. 4.</p>
<p>Tan, S.; Li, B. (2014): Stacked convolutional auto-encoders for steganalysis of<br>digital</p>
<p>images. Signal and Information Processing Association Annual Summit and<br>Conference,</p>
<p>pp. 1-4.</p>
<p>Tang, W.; Tan, S.; Li, B.; Huang, J. (2017): Automatic steganographic distortion</p>
<p>learning using a generative adversarial network. IEEE Signal Processing Letters,<br>vol. 24,</p>
<p>no. 10, pp. 1547-1551.</p>
<p>Uchida, Y.; Nagai, Y.; Sakazawa, S.; Satoh, S. I. (2017): Embedding watermarks<br>into</p>
<p>deep neural networks. Proceedings of the 2017 ACM on International Conference on</p>
<p>Multimedia Retrieval, pp. 269-277.</p>
<p>Volkhonskiy, D.; Nazarov, I.; Borisenko, B.; Burnaev, E. (2017): Steganographic</p>
<p>generative adversarial networks. Multimedia.</p>
<p>Wang, T. C.; Liu, M. Y.; Zhu, J. Y.; Liu, G.; Tao, A. et al. (2018):<br>Video-to-video</p>
<p>synthesis. Computer Vision and Pattern Recognition.</p>
<p>Wang, Q.; Chan, A. B. (2018): CNN+CNN: Convolutional decoders for image</p>
<p>captioning. Computer Vision and Pattern Recognition.</p>
<p>Westfeld, A. (2001): F5-A steganographic algorithm. Information Hiding: 4th</p>
<p>International Workshop, vol. 2137, pp. 289.</p>
<p>Wichers, N.; Villegas, R.; Erhan, D.; Lee, H. (2018): Hierarchical long-term<br>video</p>
<p>prediction without supervision. International Conference on Machine Learning.</p>
<p>Wu, H. Z.; Wang, H. X.; Shi, Y. Q. (2016): Can machine learn steganography?-</p>
<p>Processing.</p>
<p>Yang, Y.; Lalitha, A.; Lee, J.; Lott, C. (2018): Automatic grammar augmentation<br>for</p>
<p>robust voice command recognition. Computation and Language.</p>
<p>Yi, Z.; Zhang, H. R.; Tan, P.; Gong, M. (2017): DualGAN: Unsupervised dual<br>learning for</p>
<p>image-to-image translation. International Conference on Computer Vision, pp.<br>2868-2876.</p>
<p>Yu, J.; Zhan, Y.; Yang, J.; Kang, X. (2016): A multi-purpose image<br>counter-antiforensic method using convolutional neural networks. International<br>Workshop on Digital</p>
<p>Watermarking, pp. 3-15.</p>
<p>Yuan, C.; Li, X.; Wu, Q. J.; Li, J.; Sun, X. (2017): Fingerprint liveness<br>detection from</p>
<p>different fingerprint materials using convolutional neural network and principal</p>
<p>component analysis. Computers, Materials &amp; Continua, vol. 53, no. 3, pp.357-371.</p>
<p>Yuan, C.; Xia, Z.; Sun, X. (2017): Coverless image steganography based on SIFT<br>and</p>
<p>BOF. Journal of Internet Technology, vol. 18, no. 2, pp. 435-442.</p>
<p>Zeng, J.; Tan, S.; Li, B.; Huang, J. (2018): Large-scale jpeg image steganalysis<br>using</p>
<p>hybrid deep-learning framework. IEEE Transactions on Information Forensics and</p>
<p>Security, vol. 13, no. 5, pp. 1200-1214.</p>
<p>Zhang, J.; Huang, H.; Wang, L.; Lin, H.; Gao, D. (2017): Coverless text<br>information</p>
<p>hiding method using the frequent words hash. International Journal Network<br>Security,</p>
<p>vol. 19, no. 6, pp. 1016-1023.</p>
<p>Zhang, J.; Shen, J.; Wang, L.; Lin, H. (2016): Coverless text information hiding</p>
<p>method based on the word rank map. International Conference on Cloud Computing<br>and</p>
<p>Security, pp. 145-155.</p>
<p>Zhang, R.; Dong, S.; Liu, J. (2018): Invisible steganography via generative<br>adversarial</p>
<p>networks. Multimedia Tools and Applications, pp. 1-7.</p>
<p>Zhang, R.; Zhu, F.; Liu, J.; Liu, G. (2018): Efficient feature learning and<br>multi-size</p>
<p>image steganalysis based on CNN. Multimedia.</p>
<p>Zheng, M.; Zhang, S. H.; Wu, S.; Jiang, J. (2017): Steganographer detection via<br>deep</p>
<p>residual network. IEEE International Conference on Multimedia and Expo, pp.<br>235-240.</p>
<p>Zhang, X.; Wang, S. (2005): Steganography using multiple-base notational system<br>and</p>
<p>human vision sensitivity. IEEE Signal Processing Letters, vol. 12, no. 1, pp.<br>67-70.</p>
<p>Zhou, Z.; Cao, Y.; Sun, X. (2016): Coverless information hiding based on<br>bag-of-words</p>
<p>model of image. Journal of Applied Sciences, vol. 34, no. 5, pp. 527-536.</p>
<p>Zhou, Z.; Sun, H.; Harit, R.; Chen, X.; Sun, X. (2015): Coverless image</p>
<p>steganography without embedding. International Conference on Cloud Computing and</p>
<p>Security, pp. 123-132.</p>
<p>Zhu, J. Y.; Park, T.; Isola, P.; Efros, A. A. (2017): Unpaired image-to-image</p>
<p>translation using cycle-consistent adversarial networks. International<br>Conference on</p>
<p>Computer Vision, pp. 2223-2232.</p>
<p>Zhuang, J.; Yang, J. (2018): ShelfNet for real-time semantic segmentation.<br>Computer</p>
<p>Vision and Pattern Recognition.</p>

      
    </div>
    
    
    

    

      <div>
        
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
        
      </div>

      
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Steganography/" rel="tag"><i class="fa fa-tag"></i> Steganography</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/09/29/高斯建模图像残差及隐秘信息/" rel="next" title="高斯建模图像残差及隐秘信息">
                <i class="fa fa-chevron-left"></i> 高斯建模图像残差及隐秘信息
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/10/10/DL-stganography-summarize-2015-2018/" rel="prev" title="DL stganography summarize(2015-2018)">
                DL stganography summarize(2015-2018) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  <div onclick="showGitment()" id="gitment_title" class="gitment_title">显示 Gitment 评论</div>
  <div id="container" style="display:none"></div>
  <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
  <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
  <script>
  const myTheme = {
  render(state, instance) {
  const container = document.createElement('div');
  container.lang = "en-US";
    container.className = 'gitment-container gitment-root-container';
   container.appendChild(instance.renderHeader(state, instance));
    container.appendChild(instance.renderEditor(state, instance));
    container.appendChild(instance.renderComments(state, instance));
    container.appendChild(instance.renderFooter(state, instance));
    return container;
    }
}
function showGitment() {
$("#gitment_title").attr("style", "display:none");
$("#container").attr("style", "").addClass("gitment_container");
var gitment = new Gitment({
id: window.location.pathname,
theme: myTheme,
owner: '',
repo: '',
oauth: {
client_id: '9f634ff1d663061b7b31',
client_secret: '45166540e0b361ee1919e27f29ad9aac978d8437'
}
});
gitment.render('container');
}
</script>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/jiansheng.jpg"
               alt="Wu Tian" />
          <p class="site-author-name" itemprop="name">Wu Tian</p>
           
              <p class="site-description motion-element" itemprop="description">Record</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">12</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/fennudehaogua" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://mail.google.com/mail/u/0/?tab=wm#inbox" target="_blank" title="E-Mail">
                  
                    <i class="fa fa-fw fa-envelope"></i>
                  
                    
                      E-Mail
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.facebook.com/profile.php?id=100017135643802" target="_blank" title="FB Page">
                  
                    <i class="fa fa-fw fa-facebook"></i>
                  
                    
                      FB Page
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.youtube.com/channel/UC8TkFUpWAS2wzj34ijgAZGA?view_as=subscriber" target="_blank" title="YouTube">
                  
                    <i class="fa fa-fw fa-youtube"></i>
                  
                    
                      YouTube
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.ws.binghamton.edu/fridrich/?tdsourcetag=s_pctim_aiomsg" title="Fridrich" target="_blank">Fridrich</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://imkira.com/" title="Kira" target="_blank">Kira</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#摘要："><span class="nav-number">1.</span> <span class="nav-text">摘要：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#引言"><span class="nav-number">2.</span> <span class="nav-text">引言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#相关工作"><span class="nav-number">3.</span> <span class="nav-text">相关工作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#深度学习"><span class="nav-number">3.1.</span> <span class="nav-text">深度学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#信息隐藏"><span class="nav-number">3.2.</span> <span class="nav-text">信息隐藏</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#水印"><span class="nav-number">3.3.</span> <span class="nav-text">水印</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#无载体信息隐藏"><span class="nav-number">3.4.</span> <span class="nav-text">无载体信息隐藏</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#隐写分析"><span class="nav-number">3.5.</span> <span class="nav-text">隐写分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于深度学习的图像信息隐藏技术"><span class="nav-number">4.</span> <span class="nav-text">基于深度学习的图像信息隐藏技术</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基于深度学习的隐写算法"><span class="nav-number">4.1.</span> <span class="nav-text">基于深度学习的隐写算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#对抗性方法的隐写算法"><span class="nav-number">4.1.1.</span> <span class="nav-text">对抗性方法的隐写算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#隐藏整个秘密图像的隐写算法"><span class="nav-number">4.1.2.</span> <span class="nav-text">隐藏整个秘密图像的隐写算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于深度学习的水印算法"><span class="nav-number">4.2.</span> <span class="nav-text">基于深度学习的水印算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于深度学习的无载体信息隐藏算法"><span class="nav-number">4.3.</span> <span class="nav-text">基于深度学习的无载体信息隐藏算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于深度学习的隐写分析"><span class="nav-number">4.4.</span> <span class="nav-text">基于深度学习的隐写分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#改进或迁移网络模型结构的隐写分析方法"><span class="nav-number">4.4.1.</span> <span class="nav-text">改进或迁移网络模型结构的隐写分析方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基于迁移学习的隐写分析方法"><span class="nav-number">4.4.2.</span> <span class="nav-text">基于迁移学习的隐写分析方法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#评估与比较"><span class="nav-number">5.</span> <span class="nav-text">评估与比较</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结论与未来工作"><span class="nav-number">6.</span> <span class="nav-text">结论与未来工作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">7.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wu Tian</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  





  

  

  

  

  

  


<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"mobile":{"show":false},"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"/live2dw/assets/assets/haruto.model.json"}});</script></body>
</html>
